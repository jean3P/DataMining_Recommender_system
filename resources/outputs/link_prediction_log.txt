collecting all words and their counts
PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
collected 5 word types from a corpus of 2500 raw words and 250 sentences
Creating a fresh vocabulary
Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 5 unique words (100.00% of original 5, drops 0)', 'datetime': '2023-11-18T16:20:32.782888', 'gensim': '4.3.2', 'python': '3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}
Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 2500 word corpus (100.00% of original 2500, drops 0)', 'datetime': '2023-11-18T16:20:32.794880', 'gensim': '4.3.2', 'python': '3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}
deleting the raw counts dictionary of 5 items
sample=0.001 downsamples 5 most-common words
Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 186.68841244171315 word corpus (7.5%% of prior 2500)', 'datetime': '2023-11-18T16:20:32.795885', 'gensim': '4.3.2', 'python': '3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}
estimated required memory for 5 words and 10 dimensions: 2900 bytes
resetting layer weights
Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-11-18T16:20:32.798879', 'gensim': '4.3.2', 'python': '3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'}
Word2Vec lifecycle event {'msg': 'training model with 4 workers on 5 vocabulary and 10 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-11-18T16:20:32.798879', 'gensim': '4.3.2', 'python': '3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}
EPOCH 0: training on 2500 raw words (194 effective words) took 0.0s, 9482 effective words/s
EPOCH 1: training on 2500 raw words (176 effective words) took 0.0s, 12938 effective words/s
EPOCH 2: training on 2500 raw words (171 effective words) took 0.0s, 11052 effective words/s
EPOCH 3: training on 2500 raw words (167 effective words) took 0.0s, 12540 effective words/s
EPOCH 4: training on 2500 raw words (215 effective words) took 0.0s, 9588 effective words/s
Word2Vec lifecycle event {'msg': 'training on 12500 raw words (923 effective words) took 0.1s, 9333 effective words/s', 'datetime': '2023-11-18T16:20:32.897879', 'gensim': '4.3.2', 'python': '3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}
Word2Vec lifecycle event {'params': 'Word2Vec<vocab=5, vector_size=10, alpha=0.025>', 'datetime': '2023-11-18T16:20:32.897879', 'gensim': '4.3.2', 'python': '3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}
